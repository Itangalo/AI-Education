# AI och risker
En bok som handlar om AI bör också ta upp risker med AI. De risker som tas upp här är har inte utgångspunkt i skola och utbildning, utan har ett mer allmänt perspektiv på risker med AI. I kapitlet med några möjliga framtidsscenarion diskuteras hur skolan kan påverkas. Flera av riskerna som beskrivs i det här kapitlet överlappar varandra.

## Risker i nära framtid

### Arbetslöshet
En naturlig följd av AI blir allt mer kompetent är att den kan ta hand om allt fler uppgifter – även inom arbetslivet. När sådana förändringar sker långsamt leder det till att vissa arbetsuppgifter eller delar av arbetsuppgifter byts ut mot annat arbete, och på sikt att vissa yrken blir ovanligare (medan andra blir vanligare). När effektiviseringar sker snabbare, vilket verkar vara fallet med AI-utvecklingen, kan det leda till att stora delar av arbetsuppgifter i ett jobb försvinner. Det ger sämre möjligheter att gradvis börja jobba med andra uppgifter, och större risk för uppsägningar. Om effektiviseringar går så långt att en person kan göra det jobb som tio personer gjorde tidigare kan man prata om att hela yrkeskategorier blir arbetslösa.

I mitten av mars 2023 publicerades en studie från OpenAI, OpenResearch och University of Pennsylvania som tittade på vilken inverkan GPT-4 kan ha på arbetsmarknaden i USA. Forskarna drar slutsatsen att i fyra av fem jobb är det minst tio procent av arbetsuppgifterna som påverkas, och i nästan vart femte jobb påverkas minst hälften av arbetsuppgifterna. Sammantaget bedömer de att omkring 15 procent av arbetsuppgifter i USA påverkas. Yrken på alla inkomstnivåer är berörda, men höginkomstyrken förmodligen mer än andra.[^1] En rapport från investmentbanken Goldman Sachs i slutet av mars 2023 skriver att omkring två tredjedelar av arbeten i USA och Europa i någon mån kan automatiseras av AI och att generativ AI (så som GPT-modellerna) kan ersätta upp till en fjärdedel av det mänskliga arbetet. Sammantaget bedömer de att AI kan ersätta motsvarande 300 miljoner heltidsarbeten.[^2]

Vad betyder sådana förändringar för samhället? Här är några tänkbara följder.

* Effektivisering och automatisering leder till uppsägningar och ökad arbetslöshet. Inom vissa yrken leder det till mycket stora uppsägningar, medan andra bara påverkas marginellt. Man kan tänka sig att yrkesområden som exempelvis översättare, administratör, illustratör, analytiker, copywriter, telefonsupport, juridisk rådgivare och programmerare är mer påverkade, medan exempelvis frisör, psykolog och lärare är mindre påverkade.[^3] Om arbetslöshet ökar snabbt finns risk för missnöje och oroligheter.
* Nya arbetsuppgifter och yrken dyker upp, som i stor utsträckning kompenserar för minskat behov av arbetskraft till följd av automatisering. I vissa fall handlar det om nya arbetsuppgifter inom samma yrkesområde, i andra inte, vilket ställer olika krav på omskolning.
* Effektivisering och automatisering slår hårt mot vissa delar av världen, som upplever kraftigt minskat välstånd eller sämre framtidsutsikter. Man kan tänka sig att det drabbar länder som exporterar tjänster i form av exempelvis call centers och mjukvaruutveckling. Detta leder till ökad risk för konflikter och flyktingströmmar.
* Ett fåtal aktörer som är skickliga på att använda AI slår ut de flesta andra inom vissa branscher, eftersom de kan erbjuda tjänster över hela världen till låga priser. Resurser och inflytande koncentreras till färre organisationer.
* Effektivisering och automatisering leder till ökat välstånd och välmående, då viktiga varor och tjänster blir billigare. Minskat behov av arbetskraft leder till kortare arbetsdagar och minskad stress.

Var och en av dessa punkter skulle kunna vara utgångspunkt för diskussioner och studier, och det hade kunnat vara fler punkter på listan. Den sista punkten – om ökat välstånd och välmående – sticker ut som mer positiv än de andra. Det är förmodligen också det scenario som kräver mest aktiva insatser för att nå.

### Mer ojämlik fördelning av makt och resurser
Eftersom AI-teknik i stor utsträckning utgår från träning på befintlig data finns en tydlig risk att skeva maktstrukturer lever vidare i AI-beslut. Om en AI ska rekommendera lämpliga kandidater till en chefstjänst finns det risk att vita medelålders män får omotiverade fördelar. En fördel är att det på ett helt annat sätt än med människor går att få en AI att helt bortse från exempelvis de sju diskrimineringsgrunderna, men om ”talar svenska med brytning” inte finns med bland de faktorer en AI ska ignorera kommer AI:n tradera de mönster som finns i träningsdatan. AI är bättre än människor på att objektivt följa givna regler, men om de reglerna säger att ”tala svenska med brytning” ger minuspoäng är det fel sorts likvärdighet.

Ojämlik fördelning av makt och resurser kan också uppstå när vissa företag eller andra aktörer är avsevärt bättre än andra på att utnyttja AI som verktyg. Som nämns under föregående rubrik kan det till exempel leda till att enstaka företag – som kanske till och med var små – konkurrerar ut de flesta andra. Hypotetiskt skulle en enda översättningsbyrå med några få anställda kunna erbjuda högklassiga översättningar över hela världen för en billig peng om de använde tillräckligt bra AI-teknik. (Och under förutsättning att ingen annan översättningsbyrå gör samma sak.)

Ett specialfall av företag som utnyttjar potentialen i AI och blir jättestora är de företag som skapar AI-modeller. Den ledande AI:n för att skapa bilder är sannolikt Midjourney, med 14,5 miljoner användare i maj 2023[^4]. I augusti 2022 hade de bara omkring 10 anställda[^5], och verkar i maj 2023 ha 17 anställda och ytterligare 34 personer som jobbar med moderering och användarstöd.

De som skapar välanvända AI-modeller får dubbelt inflytande, i och med att AI-modellerna har potential att påverka vilken världsbild användarna har. Vid årsskiftet 2022–2023 var det bara sex aktörer i hela världen som hade datorkraft nog att träna stora generativa AI-modeller[^6], men teknikutveckling har ökat möjligheten för mindre och oberoende aktörer att träna AI-modeller till den grad att teknikjättarna ser en klar risk att de blir omkörda[^7]. Det dämpar risken för cementering av maktförhållanden, men ökar samtidigt risken att skadliga AI-modeller dyker upp.

### Deep fake, översvämning och kraftfulla verktyg i fel händer
Att AI blir allt mer kompetent och allt mer tillgängligt betyder tyvärr också ökade möjligheter att använda AI för att skada andra.

Termen _deepfake_ står för förfalskad media, som på ett realistiskt sätt härmar riktiga människor eller andra företeelser. Första halvan av termen kommer från AI-begreppet ”deep learning”, och markerar att AI-teknik tagit förfalskningar till en ny nivå. I januari presenterade Microsoft en AI-modell som behöver så lite som tre sekunder ljudinspelning för att kunna härma någons röst[^8]. Rösthärmning har använts för att lägga den legendariske Eddie Murphys röst i nya låtar, men också för att för att låta fejkade barnbarn ringa upp mor- eller farföräldrar och säga att de hamnat i en knipa och behöver pengar – nu direkt[^9]. I maj 2023 kom exempel på deepfake i videosamtal.[^10]

Med billigare AI-teknik ökar möjligheten att inte bara använda deepfake för att lura enskilda personer, utan också bygga upp sammanhängande propaganda och vilseledande världsbilder. Med hjälp av automatisering skulle några enskilda personer kunna orkestrera diskussionsforum, nyhetsvideor, bilder och inlägg i stora sociala medier för att till exempel ifrågasätta förintelsen, måla upp en starkt vinklad bild av kriget i Ukraina eller göra människor i Europa mer positiva till Kina som världsledande nation.

Det är viktigt att poängtera att den typen av påverkan inte handlar om propagandaaffischer eller spam-mail skrivna på dåligt översatt svenska. I stället skulle det kunna vara en fejkad alldaglig användare på Facebook som vanligtvis skriver om böcker hon läser, som börjar posta om ”något jag börjat fundera över när det gäller Ukraina”. Hon delar valda artiklar och videor (där deepfakes blandas med äkta), och uttrycker snarare ”jag känner mig förvirrad, för jag får inte riktigt bilden från reglerade media att stämma” än ”det elitistiska etablissemanget ljuger för oss”. Allt medan hon också lägger upp bilder från sommarstugan, deltar i bokcirklar online och hittar nya vänner att snacka med på nätet. I bakgrunden finns en personbeskrivning som utvecklas med tiden, och är en av tusentals fejkade personer som styrs av samma avsändare.

En relaterad risk med AI-skapat innehåll på nätet är att det inte behövs samordnade och illvilliga avsändare för att innehåll skapat av människor ska dränkas av det som är skapat av maskiner. Om varje privatperson, företag och fritidsförening skapar innehåll med AI är det risk för översvämning: Av 10 bloggar om att baka med surdeg eller att vara ensamstående förälder skrivs 9 av AI; av 100 inlägg i sociala medier är 99 skrivna av AI; av 1000 kommentar och delningar kommer 999 från AI; och av 10 000 recensioner är 9 999 skrivna av AI. Och alla ser genuina ut.

På ett plan kan man fråga sig vad det spelar för roll om en människa eller AI skrivit det man läser, skapat bilden och videon man tittar på eller talat in podden som man lyssnar på. När det gäller att hitta hitta roliga saker att göra med barn i Boden är den främsta frågan hur pålitlig och användbar informationen är, inte om avsändaren är en människa eller maskin. Men det ger en olustig känsla i magen om någon man diskuterat sin vardag med visar sig vara en robot. I skrivande stund debatteras EU-lagstiftning som bland annat ska tvinga AI att vara transparenta med att det är en maskin, inte en människa, som är avsändare.

Några sista ord om risker med kraftfulla verktyg i fel händer gäller att AI inte är begränsad att agera i den digitala världen. Övervakningskameror med ansiktsigenkänningsteknik i Kina ökar möjligheten att förebygga och följa upp brott – vilket till exempel även omfattar att demonstrera för demokrati i Hongkong. Ett annat exempel är drönare för krigsföring som själva kan identifiera mål och avgöra om de ska attackeras, vilket för första gången ha använts i Libyen 2021.[^11] Det finns också något som kallas ”dual use”, där teknik som utvecklats för goda ändamål visar sig kunna användas för att göra skada. Någon som vill göra mycket skada skulle till exempel kunna ta AI som normalt används för att hitta potentiella läkemedel och i stället skapa kemiska stridsmedel.[^12]

### Kraftfulla verktyg i obetänksamma händer
”Social media was the first contact between AI and humanity, and humanity lost.”

Det här lite nedslående påståendet kommer från en debattartikel i New York Times skriven av historikern och författaren Yuval Harari[^13]. Bakgrunden till påståendet förtjänar en längre förklaring.

I moderna sociala medier visas inte innehåll bara med ”nyast överst”. Vilket innehåll som visas, när det visas, när notifieringar plingar till och hur långa laddtiderna är innan uppdateringar syns är anpassat för att öka engagemang. I bakgrunden sitter AI-algoritmer med tillgång till enorma datamängder om klickmönster och användarbeteenden, som getts målet att öka användarnas engagemang. Vid första anblick låter det som en bra eller i värsta fall harmlös idé: Om användare får se innehåll som intresserar dem är det väl bra, och skulle de inte hur urvalet sker kan de ju alltid lägga ifrån sig telefonen och göra något annat.

Problemet är att den sinnesstämning som i störst utsträckning leder till engagemang är _ilska_, vilket betyder att en AI som fått målet att öka engagemang i stor utsträckning kommer att hitta sätt att göra människor arga. Inte för att vara elak, utan för att det är vad vi indirekt bett den att göra. Inte så arga att de stänger ner fliken i webbläsaren eller till och med avslutar sitt konto, men så pass arga att de klickar vidare, skriver en kommentar eller delar ett inlägg tillsammans med två meningar om varför andra människor är dumma i huvudet.

Med tillräckligt mycket data och datorkraft kommer lösningen på uppgiften ”öka engagemang” inte stanna vid att hitta det innehåll som gör vissa typer av användare mest engagerade. Det innehåll vi konsumerar påverkar vårt tankesätt och vår världsbild, och därmed kan AI:n ta ett steg till och göra oss mer och mer lättupprörda, mer benägna att kolla flödet, och mer benägna att tänka att andra människor är dumma i huvudet. Det skulle leda till ett mer polariserat samhälle, där det är svårt att föra sansade diskussioner där mer än ett perspektiv får plats.

Moderna sociala plattformar, där plattformen har stort inflytande över vilket innehåll som visas, har förmodligen funnits sedan mitten på 00-talet.[^14] 2020 presenterades slutbetänkande för den statliga utredningen ”Det demokratiska samtalet i en digital tid”[^15]. I sammanfattningen står bland annat följande.

> Sammantaget kan utvecklingen med desinformation, propaganda och näthat få stora konsekvenser för demokratin. Motsättningar mellan grupper i samhället kan fördjupas och den mellanmänskliga tilliten skadas. På så sätt kan förutsättningarna för den allmänna opinionsbildningen raseras samtidigt som förtroendet för demokratins institutioner, såsom de beslutsfattande församlingarna, myndigheter och nyhetsmedier, påverkas. (s. 13)

AI-algoritmer i sociala medier har med stor sannolikhet bidragit till att öka näthat och polarisering. Inte för att människor ville ha det så – inte ens de som äger sociala medier – utan för att vi inte lyckades förutse och styra vilka effekter det får när man ber en AI öka antalet klick.

När AI blir ännu bättre på att uppfylla de mål vi ger dem ökar också riskerna med oväntade bieffekter. Det är med andra ord viktigt att mänskligheten inte blir en förlorare i nästa möte med AI.

## Mer avlägsna risker
### AI-apokalyps
I debatten kring risker med AI nämns ibland att ”hälften av AI-forskarna tror att det är minst 10 procents risk att AI utplånar mänskligheten”. Påståendet har ifrågasatts, inte minst för att svarsfrekvensen bara var 17 procent i enkäten som bakom påståendet.[^16] Ett mindre kontroversiellt sätt att tolka resultaten är att ”en betydande andel av AI-forskare bedömer att det är minst fem procents risk att okontrollerbar AI leder till att mänskligheten utrotas eller blir svårt skadad”.

Vad är det frågan om? Varför skulle vi uppfinna AI som ens _kan_ skada eller döda människor, varför skulle vi säga åt en AI att göra det, och varför skulle vi inte stänga av en AI som är på väg att utplåna mänskligheten?

Innan vi försöker besvara de frågorna behöver vi dock lugna ner läget lite. Ett annat sätt att formulera påståendet ovan är nämligen att ”de flesta AI-forskare bedömer att det är mycket sannolikt att mänskligheten går under på grund av AI som vi inte kan kontrollera”. Det är rimligt – viktigt – att utforska och förstå allvarliga risker, men den som grips av panik har svårt att tänka klart. Vår mänskliga civilisation _skulle kunna_ slås ut av skenande klimatförändringar, kärnvapenkrig, pandemier, asteroidnedslag, rymdvarelser och förmodligen en rad andra saker.



Personliga relationer med chattrobotar eller annan AI.
Medvetande och AI


Oro för att AI kan komma att allvarligt skada samhället, världsordningen eller mänskligheten är tillräckligt välgrundade för att många seriösa tänkare, forskare och hela organisationer arbetar för att förstå och minska de riskerna.

Riskerna med AI ökar ju mer kompetent AI:n är. Det finns flera typer av risker, men tre breda kategorier är:
1. Risk att AI används för att gynna få samtidigt som det skadar många.
2. Risk att de mål vi ger AI leder till oförutsedda och skadliga konsekvenser.
3. Risk att AI skapar egna mål som inte stämmer med våra.

De här riskerna går delvis in i varandra, och det finns risker som faller utanför de här kategorierna.

## Risk att AI gynnar få och skadar många
I den här kategorin finns ett antal befintliga AI-tekniker. Ett exempel är övervakningskameror med ansiktsigenkänningsteknik som används i Kina, vilket ökar möjligheten att förebygga och följa upp brott – vilket till exempel även omfattar att demonstrera för demokrati i Hongkong. Ett annat exempel är drönare som används i krigsföring (exempelvis i [Libyen][14]), som själva kan identifiera mål och avgöra om de ska attackeras.

Ett mycket mer diffust exempel är de AI-system som bestämmer vilket innehåll användare på sociala medier ska se. De är tillräckligt kraftfulla för att skapa vinster för de företag som äger plattformarna, men orsaker samtidigt skada i form av exempelvis psykisk ohälsa, polarisering i samhället och spridning av osanningar.

Det finns en särskild risk med högkompetent AI, i och med att det är så tillgängligt och billigt att använda. Medan saker som kärnvapen är svåra att skapa eller köpa för terroristorganisationer, så är priset för beväpnade AI-drönare så pass lågt att de skulle kunna köpas i tusentals. Någon som vill göra mycket skada skulle också kunna ta AI som normalt används för att hitta potentiella läkemedel för att skapa kemiska stridsmedel.[^17] Medan det är dyrt att skapa AI-modeller är det billigt att använda dem, och demokratisering av teknik som kan användas för massförstörelse för med sig stora risker.

## Risk för oförutsedda och skadliga konsekvenser
Även om högkompetent AI sitter i händer på folk som vill väl finns det risk för dåliga konsekvenser. I stor utsträckning hänger det samman med att AI kan leda till att ett fåtal uttalade mål eftersträvas så effektivt att andra saker blir lidande – saker som vi inte tänkte på och kanske inte hade chans att förutse när vi formulerade målen för AI:n.

Algoritmer som används i sociala plattformar är ett exempel på detta: Målet med algoritmerna är att i så hög utsträckning som möjligt hålla människor engagerade – de ska fortsätta läsa och fortsätta klicka (vilket i sig har att göra med en bred användarbas och annonsintäkter, eller för den delen att samla in data som kan användas för att träna AI). Vad är fel med att en AI hjälper till med att visa saker som du tycker är intressanta?

Ett av problemen uppstår när det visar sig att människor blir engagerade av innehåll som gör dem upprörda, vilket i sin tur leder till att sociala plattformar ofta visar inlägg och nyheter som skapar polarisering både på nätet och i samhället. Ytterligare problem uppstår när algoritmerna inte tar hänsyn till vad som är sant, utan bara vad som skapar mer klick. De problemen blir ännu större när algoritmer börjar påverka vilka åsikter människor har, och skapar starkt polariserade grupper av människor som är lätta att göra upprörda – och få klick från.

I en hypotetisk framtid med en super-AI blir det extremt viktigt vilka mål vi gett AI:n, och det visar sig att det inte är enkelt att hitta några mål som inte riskerar att spåra ur. Målet ”människor ska vara lyckliga” låter oskyldigt, men kan till exempel uppnås genom morfin-dropp. Även mycket begränsade mål har stor potential att spåra ur. Det uttrycks ibland med frasen ”you can’t fetch coffee if you’re dead”, vilket står för att en super-AI med det enda målet att fixa kaffe kommer att inse att den inte kan göra kaffe om den stängs av – vilket i sin tur kan leda till alla möjliga åtgärder för att få bort sådant som kan stänga av den (så som människor).

## Super-AI som skapar egna mål
Forskare inom AI är oense om hur troligt det är att vi kommer att uppfinna en super-AI – en AI som är minst lika bra som en människa på i princip all typ av problemlösning. Vissa forskare bedömer det som omöjligt eller extremt osannolikt inom överskådlig tid, men den genomsnittliga bedömningen har krupit tydligt närmare nutik de senaste åren. De värden som anges varierar mellan olika undersökningar, och mediangissningen anges till 100, 50 eller 30 år.

Super-AI omnämns ofta som ”strong AI” eller ”artificial general intelligence” (AGI), och många av de som arbetar inom området ser det som angeläget att vi lägger möda på att förstå och minska riskerna med en super-AI: Även om sannolikheten för att vi skapar en super-AI inom hundra år är så liten som 10 procent vore det väl investerade insatser.

En viktig sak som gör super-AI särskilt riskfyllt är möjligheten till en AI-explosion: Om en super-AI är minst lika bra som människor på problemlösning, så omfattar det även förmågan att skapa ny, bättre AI. Den nya AI:n blir ännu bättre på detta, vilket på förhållandevis kort tid skulle kunna leda till en AI som utklassar den tankeförmåga som människor kan samla ihop.

En del av forskningen inom AI-säkerhet fokuserar därför på det som kallas _AI alignment_ – att de mål som AI har ska sammanfalla med sådant som mänskligheten tycker är bra. Delar av detta handlar om att hitta sätt att säkra att AI förstår de mål som vi ger, att AI följer de målen, och att AI:n själv inte kan ändra målen. Ett betydande problem är att AI i form av neurala nätverk i mycket stor utsträckning är svarta lådor, där man ser vad som kommer ut men inte kan se hur AI:n kommit fram till ett visst svar eller ett visst beslut.

Forskning på AI-säkerhet går framåt, men ett problem är att ekonomiska, militära och andra intressen gör att AI-teknik går framåt mycket fortare.

”Men kan vi inte bara dra ut sladden om en super-AI visar sig vilja skada oss människor?” Kanske. Om det verkligen är en super-AI förstår den människor tillräckligt väl för att veta var gränsen går, och är kapabel att säkra sin överlevnad även om det börjar ske på bekostnad av människor. Vi kan jämföra med fossilindustrin och klimatförändringar: Det står utom allt rimligt tvivel att våra utsläpp av växthusgaser, mycket på grund av fossilindustrin, skadar mänskligheten som helhet – på ett allvarligt och kostsamt sätt. Ändå är vi oförmögna att agera för att stoppa det.

## Andra risker
Några andra risker med allt mer AI beskrivs kortfattat nedan.

* **Skeva maktstrukturer kan befästas.** Eftersom AI-teknik i stor utsträckning utgår från träning på befintlig data finns en tydlig risk att skeva maktstrukturer lever vidare i AI-beslut. Om en AI ska rekommendera lämpliga kandidater till en chefstjänst finns det risk att vita medelålders män får omotiverade fördelar.
* **Mänskligt innehåll kan dränks av AI-innehåll.** Om GPT-3.5 tränats på text motsvarande 57 miljarder människoliv av läsning kan man konstatera att den mesta texten på internet _inte_ skapats av människor. Med allt skickligare AI kommer det bli svårare att hitta text som faktiskt skrivits av en människa, och svårare att veta när man hittat det.
* **Resurser och makt kan fördelas än mer ojämlikt.** Även om AI är förhållandevis billigt att använda är det dyrt att framställa och kräver enorma mängder data. De få aktörer som kan ta fram kraftfulla AI kan få stort inflytande – både i termer av ekonomisk produktion och vad gäller påverkan på information som människor tar del av. De stora generativa AI-modeller som finns tillgängliga idag kommer från bara sex aktörer.[^18]
* **Snabba förändringar på arbetsmarknaden.** AI-utveckling kan leda till att arbetsmarknaden krymper eller att de kompetenser som efterfrågas ändras på ett sätt som gör många arbetslösa. Det kan både skapa problem för de drabbade människorna och oroligheter på samhällsnivå.

[^1]:	[https://doi.org/10.48550/arXiv.2303.10130][1]

[^2]:	[https://www.ansa.it/documents/1680080409454\_ert.pdf][2]

[^3]:	Det kan dock påpekas att en del analyser som går att hitta på nätet säger helt olika saker om vissa yrken, så som grafisk designer och programmerare.

[^4]:	[https://approachableai.com/midjourney-statistics/][3]

[^5]:	[https://www.theregister.com/2022/08/01/david\_holz\_midjourney/][4]

[^6]:	https://arxiv.org/abs/2301.04655

[^7]:	[https://www.semianalysis.com/p/google-we-have-no-moat-and-neither][5]

[^8]:	[https://arxiv.org/abs/2301.02111][6]

[^9]:	[https://www.washingtonpost.com/technology/2023/03/05/ai-voice-scam/][7]

[^10]:	[https://gizmodo.com/deepfake-ai-scammer-money-wiring-china-1850461160][8]

[^11]:	[https://www.newscientist.com/article/2278852-drones-may-have-attacked-humans-fully-autonomously-for-the-first-time/][9]

[^12]:	[https://futureoflife.org/podcast/sean-ekins-on-regulating-ai-drug-discovery/][10]

[^13]:	[https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html][11]

[^14]:	Svenska Wikipedia var Myspace, grundat 2004, det enda större sociala nätverket i Sverige innan Facebook nådde Sverige 2007. LunarStorm, grundat 2000, användes innan dess men hade troligtvis inte avancerade algoritmer för att välja ut innehåll.

[^15]:	[https://www.regeringen.se/rattsliga-dokument/statens-offentliga-utredningar/2020/09/sou-202056/][12]

[^16]:	En bra genomgång går att hitta på [https://aiguide.substack.com/p/do-half-of-ai-researchers-believe][13].

[^17]:	https://futureoflife.org/podcast/sean-ekins-on-regulating-ai-drug-discovery/

[^18]:	https://arxiv.org/abs/2301.04655

[1]:	https://doi.org/10.48550/arXiv.2303.10130
[2]:	https://www.ansa.it/documents/1680080409454_ert.pdf
[3]:	https://approachableai.com/midjourney-statistics/
[4]:	https://www.theregister.com/2022/08/01/david_holz_midjourney/ "Intervju i The Register"
[5]:	https://www.semianalysis.com/p/google-we-have-no-moat-and-neither "Semianalytics: Google "We Have No Moat, And Neither Does OpenAI""
[6]:	https://arxiv.org/abs/2301.02111 "Arxiv: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers"
[7]:	https://www.washingtonpost.com/technology/2023/03/05/ai-voice-scam/ "Exempel på telefon-scam, Washington Post"
[8]:	https://gizmodo.com/deepfake-ai-scammer-money-wiring-china-1850461160 "Artikel i Gizmodo"
[9]:	https://www.newscientist.com/article/2278852-drones-may-have-attacked-humans-fully-autonomously-for-the-first-time/ "Artikel i New Scientist"
[10]:	https://futureoflife.org/podcast/sean-ekins-on-regulating-ai-drug-discovery/ "Intervju med läkemedelsforskaren Sean Ekin."
[11]:	https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html "NYT: You Can Have the Blue Pill or the Red Pill, and We’re Out of Blue Pills"
[12]:	https://www.regeringen.se/rattsliga-dokument/statens-offentliga-utredningar/2020/09/sou-202056/ "SOU 2020:56"
[13]:	https://aiguide.substack.com/p/do-half-of-ai-researchers-believe
[14]:	https://www.newscientist.com/article/2278852-drones-may-have-attacked-humans-fully-autonomously-for-the-first-time/