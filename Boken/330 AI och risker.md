# AI och risker
En bok som handlar om AI bör också ta upp risker med AI. De risker som tas upp här är har inte utgångspunkt i skola och utbildning, utan har ett mer allmänt perspektiv på risker med AI. I kapitlet med några möjliga framtidsscenarion diskuteras hur skolan kan påverkas. Flera av riskerna som beskrivs i det här kapitlet överlappar varandra.

## Risker i nära framtid

### Arbetslöshet
En naturlig följd av AI blir allt mer kompetent är att den kan ta hand om allt fler uppgifter – även inom arbetslivet. När sådana förändringar sker långsamt leder det till att vissa arbetsuppgifter eller delar av arbetsuppgifter byts ut mot annat arbete, och på sikt att vissa yrken blir ovanligare (medan andra blir vanligare). När effektiviseringar sker snabbare, vilket verkar vara fallet med AI-utvecklingen, kan det leda till att stora delar av arbetsuppgifter i ett jobb försvinner. Det ger sämre möjligheter att gradvis börja jobba med andra uppgifter, och större risk för uppsägningar. Om effektiviseringar går så långt att en person kan göra det jobb som tio personer gjorde tidigare kan man prata om att hela yrkeskategorier blir arbetslösa.

I mitten av mars 2023 publicerades en studie från OpenAI, OpenResearch och University of Pennsylvania som tittade på vilken inverkan GPT-4 kan ha på arbetsmarknaden i USA. Forskarna drar slutsatsen att i fyra av fem jobb är det minst tio procent av arbetsuppgifterna som påverkas, och i nästan vart femte jobb påverkas minst hälften av arbetsuppgifterna. Sammantaget bedömer de att omkring 15 procent av arbetsuppgifter i USA påverkas. Yrken på alla inkomstnivåer är berörda, men höginkomstyrken förmodligen mer än andra.[^1] En rapport från investmentbanken Goldman Sachs i slutet av mars 2023 skriver att omkring två tredjedelar av arbeten i USA och Europa i någon mån kan automatiseras av AI och att generativ AI (så som GPT-modellerna) kan ersätta upp till en fjärdedel av det mänskliga arbetet. Sammantaget bedömer de att AI kan ersätta motsvarande 300 miljoner heltidsarbeten.[^2]

Vad betyder sådana förändringar för samhället? Här är några tänkbara följder.

* Effektivisering och automatisering leder till uppsägningar och ökad arbetslöshet. Inom vissa yrken leder det till mycket stora uppsägningar, medan andra bara påverkas marginellt. Man kan tänka sig att yrkesområden som exempelvis översättare, administratör, illustratör, analytiker, copywriter, telefonsupport, juridisk rådgivare och programmerare är mer påverkade, medan exempelvis frisör, psykolog och lärare är mindre påverkade.[^3] Om arbetslöshet ökar snabbt finns risk för missnöje och oroligheter.
* Nya arbetsuppgifter och yrken dyker upp, som i stor utsträckning kompenserar för minskat behov av arbetskraft till följd av automatisering. I vissa fall handlar det om nya arbetsuppgifter inom samma yrkesområde, i andra inte, vilket ställer olika krav på omskolning.
* Effektivisering och automatisering slår hårt mot vissa delar av världen, som upplever kraftigt minskat välstånd eller sämre framtidsutsikter. Man kan tänka sig att det drabbar länder som exporterar tjänster i form av exempelvis call centers och mjukvaruutveckling. Detta leder till ökad risk för konflikter och flyktingströmmar.
* Ett fåtal aktörer som är skickliga på att använda AI slår ut de flesta andra inom vissa branscher, eftersom de kan erbjuda tjänster över hela världen till låga priser. Resurser och inflytande koncentreras till färre organisationer.
* Effektivisering och automatisering leder till ökat välstånd och välmående, då viktiga varor och tjänster blir billigare. Minskat behov av arbetskraft leder till kortare arbetsdagar och minskad stress.

Var och en av dessa punkter skulle kunna vara utgångspunkt för diskussioner och studier, och det hade kunnat vara fler punkter på listan. Den sista punkten – om ökat välstånd och välmående – sticker ut som mer positiv än de andra. Det är förmodligen också det scenario som kräver mest aktiva insatser för att nå.

### Mer ojämlik fördelning av makt och resurser
Eftersom AI-teknik i stor utsträckning utgår från träning på befintlig data finns en tydlig risk att skeva maktstrukturer lever vidare i AI-beslut. Om en AI ska rekommendera lämpliga kandidater till en chefstjänst finns det risk att vita medelålders män får omotiverade fördelar. En fördel är att det på ett helt annat sätt än med människor går att få en AI att helt bortse från exempelvis de sju diskrimineringsgrunderna, men om ”talar svenska med brytning” inte finns med bland de faktorer en AI ska ignorera kommer AI:n tradera de mönster som finns i träningsdatan. AI är bättre än människor på att objektivt följa givna regler, men om de reglerna säger att ”tala svenska med brytning” ger minuspoäng är det fel sorts likvärdighet.

Ojämlik fördelning av makt och resurser kan också uppstå när vissa företag eller andra aktörer är avsevärt bättre än andra på att utnyttja AI som verktyg. Som nämns under föregående rubrik kan det till exempel leda till att enstaka företag – som kanske till och med var små – konkurrerar ut de flesta andra. Hypotetiskt skulle en enda översättningsbyrå med några få anställda kunna erbjuda högklassiga översättningar över hela världen för en billig peng om de använde tillräckligt bra AI-teknik. (Och under förutsättning att ingen annan översättningsbyrå gör samma sak.)

Ett specialfall av företag som utnyttjar potentialen i AI och blir jättestora är de företag som skapar AI-modeller. Den ledande AI:n för att skapa bilder är sannolikt Midjourney, med 14,5 miljoner användare i maj 2023[^4]. I augusti 2022 hade de bara omkring 10 anställda[^5], och verkar i maj 2023 ha 17 anställda och ytterligare 34 personer som jobbar med moderering och användarstöd.

De som skapar välanvända AI-modeller får dubbelt inflytande, i och med att AI-modellerna har potential att påverka vilken världsbild användarna har. Vid årsskiftet 2022–2023 var det bara sex aktörer i hela världen som hade datorkraft nog att träna stora generativa AI-modeller[^6], men teknikutveckling har ökat möjligheten för mindre och oberoende aktörer att träna AI-modeller till den grad att teknikjättarna ser en klar risk att de blir omkörda[^7]. Det dämpar risken för cementering av maktförhållanden, men ökar samtidigt risken att skadliga AI-modeller dyker upp.

### Deep fake, översvämning och kraftfulla verktyg i fel händer
Att AI blir allt mer kompetent och allt mer tillgängligt betyder tyvärr också ökade möjligheter att använda AI för att skada andra.

Termen _deepfake_ står för förfalskad media, som på ett realistiskt sätt härmar riktiga människor eller andra företeelser. Första halvan av termen kommer från AI-begreppet ”deep learning”, och markerar att AI-teknik tagit förfalskningar till en ny nivå. I januari presenterade Microsoft en AI-modell som behöver så lite som tre sekunder ljudinspelning för att kunna härma någons röst[^8]. Rösthärmning har använts för att lägga den legendariske Eddie Murphys röst i nya låtar, men också för att för att låta fejkade barnbarn ringa upp mor- eller farföräldrar och säga att de hamnat i en knipa och behöver pengar – nu direkt[^9]. I maj 2023 kom exempel på deepfake i videosamtal.[^10]

Med billigare AI-teknik ökar möjligheten att inte bara använda deepfake för att lura enskilda personer, utan också bygga upp sammanhängande propaganda och vilseledande världsbilder. Med hjälp av automatisering skulle några enskilda personer kunna orkestrera diskussionsforum, nyhetsvideor, bilder och inlägg i stora sociala medier för att till exempel ifrågasätta förintelsen, måla upp en starkt vinklad bild av kriget i Ukraina eller göra människor i Europa mer positiva till Kina som världsledande nation.

Det är viktigt att poängtera att den typen av påverkan inte handlar om propagandaaffischer eller spam-mail skrivna på dåligt översatt svenska. I stället skulle det kunna vara en fejkad alldaglig användare på Facebook som vanligtvis skriver om böcker hon läser, som börjar posta om ”något jag börjat fundera över när det gäller Ukraina”. Hon delar valda artiklar och videor (där deepfakes blandas med äkta), och uttrycker snarare ”jag känner mig förvirrad, för jag får inte riktigt bilden från reglerade media att stämma” än ”det elitistiska etablissemanget ljuger för oss”. Allt medan hon också lägger upp bilder från sommarstugan, deltar i bokcirklar online och hittar nya vänner att snacka med på nätet. I bakgrunden finns en personbeskrivning som utvecklas med tiden, och är en av tusentals fejkade personer som styrs av samma avsändare.

En relaterad risk med AI-skapat innehåll på nätet är att det inte behövs samordnade och illvilliga avsändare för att innehåll skapat av människor ska dränkas av det som är skapat av maskiner. Om varje privatperson, företag och fritidsförening skapar innehåll med AI är det risk för översvämning: Av 10 bloggar om att baka med surdeg eller att vara ensamstående förälder skrivs 9 av AI; av 100 inlägg i sociala medier är 99 skrivna av AI; av 1000 kommentar och delningar kommer 999 från AI; och av 10 000 recensioner är 9 999 skrivna av AI. Och alla ser genuina ut.

På ett plan kan man fråga sig vad det spelar för roll om en människa eller AI skrivit det man läser, skapat bilden och videon man tittar på eller talat in podden som man lyssnar på. När det gäller att hitta hitta roliga saker att göra med barn i Boden är den främsta frågan hur pålitlig och användbar informationen är, inte om avsändaren är en människa eller maskin. Men det ger en olustig känsla i magen om någon man diskuterat sin vardag med visar sig vara en robot. I skrivande stund debatteras EU-lagstiftning som bland annat ska tvinga AI att vara transparenta med att det är en maskin, inte en människa, som är avsändare.

Några sista ord om risker med kraftfulla verktyg i fel händer gäller att AI inte är begränsad att agera i den digitala världen. Övervakningskameror med ansiktsigenkänningsteknik i Kina ökar möjligheten att förebygga och följa upp brott – vilket till exempel även omfattar att demonstrera för demokrati i Hongkong. Ett annat exempel är drönare för krigsföring som själva kan identifiera mål och avgöra om de ska attackeras, vilket för första gången ha använts i Libyen 2021.[^11] Det finns också något som kallas ”dual use”, där teknik som utvecklats för goda ändamål visar sig kunna användas för att göra skada. Någon som vill göra mycket skada skulle till exempel kunna ta AI som normalt används för att hitta potentiella läkemedel och i stället skapa kemiska stridsmedel.[^12]

### Kraftfulla verktyg i obetänksamma händer
”Social media was the first contact between AI and humanity, and humanity lost.”

Det här lite nedslående påståendet kommer från en debattartikel i New York Times skriven av historikern och författaren Yuval Harari[^13]. Bakgrunden till påståendet förtjänar en längre förklaring.

I moderna sociala medier visas inte innehåll bara med ”nyast överst”. Vilket innehåll som visas, när det visas, när notifieringar plingar till och hur långa laddtiderna är innan uppdateringar syns är anpassat för att öka engagemang. I bakgrunden sitter AI-algoritmer med tillgång till enorma datamängder om klickmönster och användarbeteenden, som getts målet att öka användarnas engagemang. Vid första anblick låter det som en bra eller i värsta fall harmlös idé: Om användare får se innehåll som intresserar dem är det väl bra, och skulle de inte hur urvalet sker kan de ju alltid lägga ifrån sig telefonen och göra något annat.

Problemet är att den sinnesstämning som i störst utsträckning leder till engagemang är _ilska_, vilket betyder att en AI som fått målet att öka engagemang i stor utsträckning kommer att hitta sätt att göra människor arga. Inte för att vara elak, utan för att det är vad vi indirekt bett den att göra. Inte så arga att de stänger ner fliken i webbläsaren eller till och med avslutar sitt konto, men så pass arga att de klickar vidare, skriver en kommentar eller delar ett inlägg tillsammans med två meningar om varför andra människor är dumma i huvudet.

Med tillräckligt mycket data och datorkraft kommer lösningen på uppgiften ”öka engagemang” inte stanna vid att hitta det innehåll som gör vissa typer av användare mest engagerade. Det innehåll vi konsumerar påverkar vårt tankesätt och vår världsbild, och därmed kan AI:n ta ett steg till och göra oss mer och mer lättupprörda, mer benägna att kolla flödet, och mer benägna att tänka att andra människor är dumma i huvudet. Det skulle leda till ett mer polariserat samhälle, där det är svårt att föra sansade diskussioner där mer än ett perspektiv får plats.

Moderna sociala plattformar, där plattformen har stort inflytande över vilket innehåll som visas, har förmodligen funnits sedan mitten på 00-talet.[^14] 2020 presenterades slutbetänkande för den statliga utredningen ”Det demokratiska samtalet i en digital tid”[^15]. I sammanfattningen står bland annat följande.

> Sammantaget kan utvecklingen med desinformation, propaganda och näthat få stora konsekvenser för demokratin. Motsättningar mellan grupper i samhället kan fördjupas och den mellanmänskliga tilliten skadas. På så sätt kan förutsättningarna för den allmänna opinionsbildningen raseras samtidigt som förtroendet för demokratins institutioner, såsom de beslutsfattande församlingarna, myndigheter och nyhetsmedier, påverkas. (s. 13)

AI-algoritmer i sociala medier har med stor sannolikhet bidragit till att öka näthat och polarisering. Inte för att människor ville ha det så – inte ens de som äger sociala medier – utan för att vi inte lyckades förutse och styra vilka effekter det får när man ber en AI öka antalet klick.

När AI blir ännu bättre på att uppfylla de mål vi ger dem ökar också riskerna med oväntade bieffekter. Det är med andra ord viktigt att mänskligheten inte blir en förlorare i nästa möte med AI.

## Mer avlägsna risker
### AI-apokalyps
I debatten kring risker med AI nämns ibland att ”hälften av AI-forskarna tror att det är minst 10 procents risk att AI utplånar mänskligheten”. Påståendet har ifrågasatts, inte minst för att svarsfrekvensen bara var 17 procent i enkäten som bakom påståendet.[^16] Ett mindre kontroversiellt sätt att tolka resultaten är att ”en betydande andel av AI-forskare bedömer att det är minst fem procents risk att okontrollerbar AI leder till att mänskligheten utrotas eller blir svårt skadad”.

Vad är det frågan om? Varför skulle vi uppfinna AI som ens _kan_ skada eller döda människor, varför skulle vi säga åt en AI att göra det, och varför skulle vi inte stänga av en AI som är på väg att utplåna mänskligheten?

Innan vi försöker besvara de frågorna behöver vi dock lugna ner läget lite. Ett annat sätt att formulera resultatet från enkätundersökningen är nämligen att ”de flesta AI-forskare bedömer att det är mycket sannolikt att mänskligheten går under på grund av AI som vi inte kan kontrollera”. Det är viktigt att förstå allvarliga risker, men den som grips av panik har svårt att tänka klart. Vår mänskliga civilisation _skulle kunna_ slås ut av skenande klimatförändringar, kärnvapenkrig, pandemier, asteroidnedslag, rymdvarelser och förmodligen en rad andra saker. Vill vi agera klokt behöver vi förstå mekanismerna bakom riskerna, för att kunna bedöma hur stora de är och vad vi kan göra för att minimera eller helt undvika dem.

De existentiella riskerna med AI hänger huvudsakligen ihop med två saker. Det ena kallas _generell artificiell intelligens_ (AGI) och det andra kallas ibland för kung Midas-problemet.

#### Generell AI och super-AI
Det finns ingen allmänt accepterad definition av generell AI, men alla varianter går ut på en AI som klarar av att resonera eller problemlösa lika bra som människor, i stort sett oavsett område. Den avgörande av dessa förmågor är förmågan att bygga eller förbättra artificiell intelligens. När en AI blir minst lika bra som mänskliga experter på det kommer vägen till en ännu mer kompetent AI bli kortare, och sedan kortare och kortare för varje generation av AI som skapas.

När AI-utvecklingen till slut planar ut har sannolikt en super-AI utvecklats, med förmåga att tänka snabbare, längre och djupare än den samlade mänskligheten kan göra. Beroende på hur snabbt det går från en AI på gränsen till mänsklig förmåga till en super-AI pratar man om ”soft AI takeoff” (som tar år eller decennier) eller ”hard AI takeoff” (som tar dagar eller månader).[^17] Hur snabbt den utvecklingen går spelar stor roll för möjligheterna för oss att lära oss kontrollera AI:n under tiden, och helst skulle vi förstås ha löst sådana problem redan innan vi har generell artificiell intelligens.

Det råder delade meningar om när AGI kan dyka upp. Vissa menar att det dröjer hundratals år, medan andra tycker sig se spår av AGI redan i GPT-4[^18]. Den genomsnittliga uppskattningen har krupit tydligt närmare nutid de senaste åren. De värden som anges varierar mellan olika undersökningar, och mediangissningen anges till 100, 50 eller 30 år. Invändningar mot AGI och utvecklingen mot super-AI omfattar bland annat att mänskligt tänkande är extremt komplext, att det efter hand kan bli radikalt svårare att skapa bättre AI-modeller (även för en AI), att tillgänglig datorkraft begränsar hur fort utvecklingen mot super-AI kan gå, och att framtiden för AI inte handlar om att bygga AGI utan svagare och mer specialiserade system.

#### Kung Midas-problemet
…

* Explainable AI
* Förstå mål, anta mål och behålla mål
* ”Value alignment” från Stuart Russel

### Kvar att skriva
* Personliga relationer med chattrobotar eller annan AI
* Medvetande och AI

[^1]:	[https://doi.org/10.48550/arXiv.2303.10130][1]

[^2]:	[https://www.ansa.it/documents/1680080409454\_ert.pdf][2]

[^3]:	Det kan dock påpekas att en del analyser som går att hitta på nätet säger helt olika saker om vissa yrken, så som grafisk designer och programmerare.

[^4]:	[https://approachableai.com/midjourney-statistics/][3]

[^5]:	[https://www.theregister.com/2022/08/01/david\_holz\_midjourney/][4]

[^6]:	https://arxiv.org/abs/2301.04655

[^7]:	[https://www.semianalysis.com/p/google-we-have-no-moat-and-neither][5]

[^8]:	[https://arxiv.org/abs/2301.02111][6]

[^9]:	[https://www.washingtonpost.com/technology/2023/03/05/ai-voice-scam/][7]

[^10]:	[https://gizmodo.com/deepfake-ai-scammer-money-wiring-china-1850461160][8]

[^11]:	[https://www.newscientist.com/article/2278852-drones-may-have-attacked-humans-fully-autonomously-for-the-first-time/][9]

[^12]:	[https://futureoflife.org/podcast/sean-ekins-on-regulating-ai-drug-discovery/][10]

[^13]:	[https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html][11]

[^14]:	Svenska Wikipedia var Myspace, grundat 2004, det enda större sociala nätverket i Sverige innan Facebook nådde Sverige 2007. LunarStorm, grundat 2000, användes innan dess men hade troligtvis inte avancerade algoritmer för att välja ut innehåll.

[^15]:	[https://www.regeringen.se/rattsliga-dokument/statens-offentliga-utredningar/2020/09/sou-202056/][12]

[^16]:	En bra genomgång går att hitta på [https://aiguide.substack.com/p/do-half-of-ai-researchers-believe][13].

[^17]:	Fallet då utvecklingen tar minuter eller timmar har fått det festliga namnet ”AI FOOM”.

[^18]:	[https://arxiv.org/abs/2303.12712][14]

[1]:	https://doi.org/10.48550/arXiv.2303.10130
[2]:	https://www.ansa.it/documents/1680080409454_ert.pdf
[3]:	https://approachableai.com/midjourney-statistics/
[4]:	https://www.theregister.com/2022/08/01/david_holz_midjourney/ "Intervju i The Register"
[5]:	https://www.semianalysis.com/p/google-we-have-no-moat-and-neither "Semianalytics: Google "We Have No Moat, And Neither Does OpenAI""
[6]:	https://arxiv.org/abs/2301.02111 "Arxiv: Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers"
[7]:	https://www.washingtonpost.com/technology/2023/03/05/ai-voice-scam/ "Exempel på telefon-scam, Washington Post"
[8]:	https://gizmodo.com/deepfake-ai-scammer-money-wiring-china-1850461160 "Artikel i Gizmodo"
[9]:	https://www.newscientist.com/article/2278852-drones-may-have-attacked-humans-fully-autonomously-for-the-first-time/ "Artikel i New Scientist"
[10]:	https://futureoflife.org/podcast/sean-ekins-on-regulating-ai-drug-discovery/ "Intervju med läkemedelsforskaren Sean Ekin."
[11]:	https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html "NYT: You Can Have the Blue Pill or the Red Pill, and We’re Out of Blue Pills"
[12]:	https://www.regeringen.se/rattsliga-dokument/statens-offentliga-utredningar/2020/09/sou-202056/ "SOU 2020:56"
[13]:	https://aiguide.substack.com/p/do-half-of-ai-researchers-believe
[14]:	https://arxiv.org/abs/2303.12712 "Arxiv: Sparks of Artificial General Intelligence: Early experiments with GPT-4"