# 11: ChatGPT and Cheating
"Cheating" can mean many different things, and it's worth remembering that using ChatGPT in writing assignments does not necessarily have to be considered cheating- just like using spell-check for essays or calculators for math tests. In some cases, it is considered cheating, while in others, it is not.

In this book, "cheating" refers to deliberately trying to deceive or mislead the teacher, and it is clear that ChatGPT makes it easier for students to cheat, especially when it comes to writing assignments outside the classroom. ChatGPT can create texts on almost anything that is taught in school, with a quality that can be perceived both in terms of content and style as being written by a human. How can one deal with such a problem?

One way to try to prevent cheating using ChatGPT is to block the web service on the school network. This is a path that some schools have taken, the most talked about case currently being all schools in the state of New York. Another possibility is to try to identify which texts are created with ChatGPT (or other similar tools). A tool called GPTZero was launched at the beginning of 2023, to do just that. It checks, among other things, if the word sequence in a text is "likely," which in that case points to the text being written by an AI of the same type as ChatGPT- which chooses words based on how well the words and sequences match texts they were trained on. The results are questionable: GPTZero can say that longer texts written by ChatGTP with a 70-80% likelihood are written by a human.

I am convinced that resourceful students will find relatively simple ways to trick AI controls and bypass network blockages: Currently, it is no harder than making slight edits to a ChatGPT text or sharing a network from one's phone. If a teacher needs written work from students and it is used as a grading basis, I therefore believe that the assignments need to be done in a monitored way- for example, not at home. I also believe that there is reason to examine how assignments can be designed so that ChatGPT can be used as a tool in the work, instead of being classified as cheating. Other paths one can imagine include trying to reduce the incentives for students to cheat, but with the focus on grades, it is a difficult battle.

Regardless of how one works, there will be cases where one suspects that students have cheated. A natural but quite time-consuming way to handle it is to ask students to explain what they submitted. If the student can do so in a way that is convincing, it is a credible way to see that the student has...

In some subjects, or parts of subjects, it is difficult to work in that way. And how to handle questions about cheating often depends on both personal attitudes and school policies.

In short, I think it is useful to think in these terms when it comes to the question of cheating with ChatGPT.

* Can the incentives for students to cheat be reduced? In many cases, this is synonymous with asking about assignments being used as grading material.
* Can graded assignments be carried out in a supervised manner? This can involve written exams with paper and pen, or a computer without an internet connection, but also, for example, asking questions orally to a few students at a time.
* Can assignments be designed so that ChatGPT is an allowed tool? It is difficult to encourage students under 18 to use ChatGPT, due to the terms of service, but if the goal of an assignment is an oral presentation, a product idea, or a functioning solution to a problem, it may not be wrong for students to seek help from various sources along the way.
* How can one work on following up suspected cheating?

Some argue that the possibility of cheating on submissions has existed for a long time and has been regularly exploited by a small but dedicated or privileged group of students. ChatGPT contributes to providing more opportunities to cheat, which means that the problem must be taken more seriously - but in a way also that the conditions become fairer.
